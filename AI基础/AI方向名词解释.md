# 强化学习

1. 任务与奖赏

- 概念：**机器**处于某一**环境**中，在**当前状态**在做出**动作**导致**状态的改变**而得到**环境的奖励反馈**。通过奖励反馈的不断学习，总结出较好的策略。
- 策略的优略取决于长期执行某一策略后得到的**累积奖赏**，而强化学习的目的就是要找到能是**长期累积奖赏最大化**的策略。

2. K-摇臂赌博机（为使得最大化单步强化学习）
   - 仅探索法：对所有摇臂进行探测，能很好地估计每个摇臂的奖赏，但是会失去最优的机会。
   - 仅利用法：一直使用目前最优摇臂，没有很好地估计摇臂的期望奖赏，很可能找不到全局的最优摇臂。
   - `E-贪心`：利用一个概率进行探索和利用的折中，以E的概率进行探索，以<img src="https://latex.codecogs.com/svg.latex?\1-E" style="zoom:90%;" />概率进行利用。
   - `softmax`：基于当前已知的摇臂平均奖赏来对探索和利用进行折中。当各摇臂平均奖赏相当时，各摇臂被选的概率也相当；当有些摇臂的平均奖赏明显高于其他时，被选取的概率也更高。
3. 有模型学习（多步强化学习）

- 假设任务对应的马尔可夫决策过程![s](https://latex.codecogs.com/png.latex?E=<X,A,P,R>>)均为已知，即机器已对环境进行了模拟，能在**机器内部模拟出环境相同或者相似**的情况。即在![s](https://latex.codecogs.com/png.latex?x)状态下执行动作![s](https://latex.codecogs.com/png.latex?a)转移到![s](https://latex.codecogs.com/png.latex?{x}')的概率是已知的，而该转移所带来的奖赏也是已知的。
- 策略评估![s](https://latex.codecogs.com/png.latex?\rightarrow )策略改进![s](https://latex.codecogs.com/png.latex?\rightarrow )策略迭代与值迭代
  - 策略评估：
    - T步累积奖赏
    - γ折扣累积奖赏

4. 免模型学习

   环境的转移概率、奖赏函数往往很难得知，学习算法**不依赖于环境建模**，则称为“免模型学习"

- 蒙特卡罗强化学习：多次“采样”，然后求取平均累积奖赏来作为期望累积奖赏的近似
- 时序差分学习：结合了动态规划与蒙特卡罗方法的思想，能做到更高效的免模型学习

5. 值函数近似

6. 模仿学习

   **从范例中进行学习**

- 直接模仿学习：直接模仿人类专家的“状态－动作” 对，推导出奖赏函数。
- 逆强化学习：设计奖赏函数往往相当困难，从人类专家提供的范例数据中反推出奖赏函数有助于解决该问题。

# 元学习

1. 定义：`Meta Learning`又称为`Learning to learn`，它不学习如何解决一个特定的问题，但可以成功学习如何解决多个任务。每当它学会解决一个新的任务，它就越有能力解决其他新的任务。

- 如分类问题中，在 `Meta training` 阶段将数据集分解为不同的 `meta task`，去学习类别变化的情况下模型的泛化能力，在`Mate Testing`阶段，面对全新的类别，不需要变动已有的模型，就可以完成分类。

2. 元学习的两级：

- 快速地获得每个任务中的知识
- 较慢地提取所有任务中学到的信息

# 小样本学习

<img src="https://tvax3.sinaimg.cn/large/005tpOh1ly1glbn5fzzoej30o80kn0yh.jpg#" alt="Snipaste_2020-12-04_11-01-24" style="zoom:150%;" />

# 迁移学习

1. 深度学习的数据假设

- 目前的数据和将来的数据有相同的特征空间且具有相同的分布
- 然而，现实中上述条件不可能成立。为了实现在研究某一领域缺乏数据，而且另一个领域具有足够的训练数据，且后者的数据分布和特征空间不同于前者，这时，可以利用迁移学习，来避免花费大量昂贵的标记数据成本。

 

2. 定义

   把之前任务中学习到的知识和技能应用到新的任务中的能力

 

3. 迁移学习的分类

| 实例迁移学习法`Instance-transfer`                | 思想：根据某个相似度匹配原则从源域数据集中挑选出和目标域数据相似度比较高的实例，并把这些实例迁移到目标域中帮助目标域模型的学习，从而解决目标域中有标签样本不足或者无标签样本的学习问题。 | 1️⃣基于boosting提升技术的实例迁移学习方法                                                                      2️⃣迁移稀疏分层概率自组织图                  3️⃣bagging集成方法和聚类算法相结合 |
| ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 特征迁移学习法`Feature-representation-transfer ` | 思想：在源域和目标域之间寻找典型特征代表来进一步弱化两个域之间的差异从而实现知识的跨领域迁移和复用 | 🅰特征选择迁移学习方法                                 思想：直接在源域和目标域中选择共有特征，把这些特征作为两个领域之间知识迁移的桥梁  🅱特征映射迁移学习方法                                  思想：首先通过特征映射把各个领域的数据从原始高维特征空间映射到低维特征空间，使得源域数据和目标域数据之间的差异性在该低维空间下缩小。然后再利用在低维空间表示的有标签源域数据训练分类器，并对目标域数据进行预测。 |
| 参数迁移学习法`Parameter-transfer`               | 思想：源域数据和目标域数据可以通过某些函数表示，而这些函数之间存在某些共同的参数.寻找源域数据和目标域数据之间可以共享的参数信息从而可以把已获得的参数知识迁移。 |                                                              |
| 关系迁移学习法`Relational-knowledge-transfer  `  | 思想：假定源域数据之间的关系和目标域数据之间的关系存在一定的相关性，通过建立源域数据的关系模型与目标域数据的关系模型的映射模型来实现关系知识的迁移 |                                                              |

 

4. 迁移学习研究方向

- 迁移什么：研究在机器学习的过程中哪些知识可以迁移到其他领域中帮助新领域的数据学习，实    现跨领域的知识迁移
- 何时迁移：关注迁移的时机，即在学习的过程中什么时候把已掌握知识迁移到目标域的学习中。迁移不当则会造成负迁移问题
- 如何迁移：找到了迁移知识之后针对具体应用问题所采用的迁移学习方法