# Pytorchä¸­åˆ©ç”¨GPUè®­ç»ƒï¼ŒCPUæµ‹è¯•

è¦å…ˆåˆ©ç”¨GPUè®­ç»ƒï¼ŒCPUæµ‹è¯•ï¼Œé‚£ä¹ˆåœ¨æ¨¡å‹**è®­ç»ƒ**æ—¶å€™ï¼Œæ˜¯èƒ½**ä¿å­˜æ¨¡å‹çš„å‚æ•°**è€Œä¸èƒ½ä¿å­˜æ•´ä¸ªæ¨¡å‹ï¼Œå¯è§**[Pytorchæ¨¡å‹ä¿å­˜æœºåˆ¶](https://www.cnblogs.com/zgqcn/p/14015720.html)**ä¾¿å¯ä»¥å­¦ä¼šæ¨¡å‹çš„***ä¿å­˜ã€åŠ è½½ã€æµ‹è¯•***

ğŸ’¥è¿™é‡Œä¸»è¦è®²ä¸€ç‚¹é‡è¦çš„ï¼Œå³åœ¨<font color='red'>**`pytorch 1.6`**</font>çš„ç‰ˆæœ¬ä¸­è®­ç»ƒæ¨¡å‹ä¿å­˜æ—¶ï¼Œ**ä¸èƒ½**ç›´æ¥ä½¿ç”¨

```python
torch.save(state_r, model_out_r_path)
```

å¦åˆ™ï¼Œåœ¨CPUæµ‹è¯•æ—¶ï¼Œç”±äºç‰ˆæœ¬çš„ä¸å…¼å®¹ä¼šå¯¼è‡´å‡ºé”™ï¼Œ**æ­£ç¡®ä½¿ç”¨**å¦‚ä¸‹ï¼š

```python
torch.save(state_g, model_out_g_path, _use_new_zipfile_serialization=False)
```

è€Œåï¼Œåœ¨æ¨¡å‹åŠ è½½æ—¶å€™ï¼Œè¦é™å®š`map_location = cpu`çš„åŠ è½½ï¼š

```python
checkpoint_r = torch.load(opt.model_r,map_location='cpu')
model_rt.load_state_dict(checkpoint_r['model'])
model_rt.eval()
optimizer_rt.load_state_dict(checkpoint_r['optimizer'])
epochs_rt = checkpoint_r['epoch']
```

GPUä¸‹è®­ç»ƒçš„æ¨¡å‹å³å¯æ–¹ä¾¿çš„åœ¨CPUç¯å¢ƒä¸­æµ‹è¯•äº†

![Snipaste_2020-11-21_15-12-23](https://tvax1.sinaimg.cn/large/005tpOh1ly1gkwtcrf273j313y04eabu.jpg)



è‹¥æ¨¡å‹å·²ç»è®­ç»ƒä¿å­˜ï¼Œä½†æ˜¯æœ‰æ²¡æœ‰ä½¿ç”¨`_use_new_zipfile_serialization=False`æ¥è¿›è¡Œçº¦æŸï¼Œé‚£ä¹ˆï¼Œå¯ä»¥åœ¨**`pytorch 1.6`**ä¸­ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œç„¶åå†æ¬¡ä½¿ç”¨`torch.save`è¿›è¡Œä¿å­˜ä¸º**ézipæ ¼å¼**ï¼š

```python
#åœ¨torch 1.6ç‰ˆæœ¬ä¸­é‡æ–°åŠ è½½ä¸€ä¸‹ç½‘ç»œå‚æ•°

model = MyModel().cuda() # å…ˆé¢„åŠ è½½æ¨¡å‹

model.load_state_dict(torch.load(pre_model))  #åŠ è½½æ¨¡å‹å‚æ•°ï¼Œpre_modelä¸ºç›´æ¥æ²¡æœ‰è®¾ç½®_use_new_zipfile_serialization=Falseè€Œæ¨¡å‹çš„å‚æ•°æ¨¡å‹

#é‡æ–°ä¿å­˜ç½‘ç»œå‚æ•°
torch.save(model.state_dict(), pre_model,_use_new_zipfile_serialization=False)
```



å¦å¤–ï¼Œç½‘ç»œæ¨¡å‹çš„å‚æ•°ä¸€èˆ¬è¾ƒå¤§ï¼Œåœ¨CPUä¸­æµ‹è¯•æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´å†…å­˜çˆ†æ»¡è€Œä½¿å¾—ç¨‹åºæ— æ³•è¿è¡Œï¼Œæ­¤æ—¶ï¼Œå¯ä»¥å°†æ¨¡å‹çš„è¾“å…¥è¿›è¡Œä¿®æ”¹ã€‚

ä»¥ä¸‹ï¼Œæ˜¯æˆ‘å°†`input`çš„å›¾åƒè®¾ç½®ä¸º`512*512`ï¼Œå¯¼è‡´äº†å†…å­˜çš„çˆ†æ»¡

![Snipaste_2020-11-21_15-21-42](https://tva2.sinaimg.cn/large/005tpOh1ly1gkwtm2ye84j30sf07qwfy.jpg)

ä¹‹åï¼Œæˆ‘å°†`input image`è£å‰ªæˆ`128 * 128`è¿›è¡ŒCPUæµ‹è¯•ï¼Œä¾¿å¯å¤§åŠŸå‘Šæˆã€‚



å…·ä½“çš„`CPU`æµ‹è¯•ä»£ç å¦‚ä¸‹ï¼Œå¯ä¾›å‚è€ƒä¸ç†è§£ï¼š

```python
from __future__ import print_function
import argparse
import torch
from PIL import Image
from torchvision.transforms import Compose, ToTensor, CenterCrop
import torchvision
from model import LapSRN_r, LapSRN_g
import torch.optim as optim
# Argument settingsss
parser = argparse.ArgumentParser(description='PyTorch LapSRN')
parser.add_argument('--input', type=str, required=False, default='/content/drive/My Drive/TestImg/val/44-512pix-speed7-ave1.tif', help='input image to use')
parser.add_argument('--model_r', type=str, default='LapSRN_r_epoch_10.pth', help='model file to use')
parser.add_argument('--model_g', type=str, default='LapSRN_g_epoch_10.pth', help='model file to use')
parser.add_argument('--outputHR2', type=str, default='./73_LapSRN_R_epochs100_HR2.tif', help='where to save the output image')
parser.add_argument('--outputHR4', type=str, default='./73_LapSRN_R_epochs100_HR4.tif', help='where to save the output image')
parser.add_argument('--cuda', action='store_true', help='use cuda')
opt = parser.parse_args()
print(opt)

model_rt = LapSRN_r()
model_gt = LapSRN_g()
optimizer_rt = optim.Adagrad(model_rt.parameters(), lr=1e-3, weight_decay=1e-5)
optimizer_gt = optim.Adagrad(model_gt.parameters(), lr=1e-3, weight_decay=1e-5)

checkpoint_r = torch.load(opt.model_r,map_location='cpu')
model_rt.load_state_dict(checkpoint_r['model'])
model_rt.eval()
optimizer_rt.load_state_dict(checkpoint_r['optimizer'])
epochs_rt = checkpoint_r['epoch']

checkpoint_g = torch.load(opt.model_g,map_location='cpu')
model_gt.load_state_dict(checkpoint_g['model'])
model_rt.eval()
optimizer_gt.load_state_dict(checkpoint_g['optimizer'])
epochs_gt = checkpoint_g['epoch']

transform = Compose(
    [
        ToTensor(),
    ])

img = Image.open(opt.input).convert('RGB')
r, g, _ = img.split()

r = transform(r)
r = r.unsqueeze(0)

g = transform(g)
g = g.unsqueeze(0)

HR_2_r, HR_4_r = model_rt(r)
HR_2_g, HR_4_g = model_gt(g)

black_2 = torch.zeros(1, 128 * 2, 128 * 2).unsqueeze(0)
HR_2 = torch.cat((HR_2_r.squeeze(0), HR_2_g.squeeze(0), black_2.squeeze(0))).unsqueeze(0)
black_4 = torch.zeros(1, 128 * 4, 128 * 4).unsqueeze(0)
HR_4 = torch.cat((HR_4_r.squeeze(0), HR_4_g.squeeze(0), black_4.squeeze(0))).unsqueeze(0)
torchvision.utils.save_image(HR_2, opt.outputHR2, padding=0) 
torchvision.utils.save_image(HR_4, opt.outputHR4, padding=0)
print("saved !")
```

